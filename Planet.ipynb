{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUBJ2XzAXg6n",
        "outputId": "6503ead2-fa95-4b27-b651-8cffc390e0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "n3iQfI00Dk44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = '/content/drive/My Drive/kepler_data.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Y9Ro7VHDB59g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the initial shape of the data\n",
        "print(\"Initial data shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoSLTCHIEGwK",
        "outputId": "6491b61d-297e-41b1-90e8-ae21b8ccb024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data shape: (9564, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec',\n",
        "    'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1',\n",
        "    'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
        "    'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2',\n",
        "    'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol', 'koi_insol_err1',\n",
        "    'koi_insol_err2', 'koi_model_snr', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2',\n",
        "    'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1',\n",
        "    'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'\n",
        "]\n",
        "\n",
        "# Target variable\n",
        "target = 'koi_disposition'\n",
        "\n",
        "# Check for missing values in the relevant columns\n",
        "missing_values = data[features + [target]].isnull().sum()\n",
        "print(\"Missing values before imputation:\")\n",
        "print(missing_values[missing_values > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE3JN-tQEKGC",
        "outputId": "37c6a188-feb1-4b93-a718-683557aec075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before imputation:\n",
            "koi_score            1510\n",
            "koi_period_err1       454\n",
            "koi_period_err2       454\n",
            "koi_time0bk_err1      454\n",
            "koi_time0bk_err2      454\n",
            "koi_impact            363\n",
            "koi_impact_err1       454\n",
            "koi_impact_err2       454\n",
            "koi_duration_err1     454\n",
            "koi_duration_err2     454\n",
            "koi_depth             363\n",
            "koi_depth_err1        454\n",
            "koi_depth_err2        454\n",
            "koi_prad              363\n",
            "koi_prad_err1         363\n",
            "koi_prad_err2         363\n",
            "koi_teq               363\n",
            "koi_insol             321\n",
            "koi_insol_err1        321\n",
            "koi_insol_err2        321\n",
            "koi_model_snr         363\n",
            "koi_steff             363\n",
            "koi_steff_err1        468\n",
            "koi_steff_err2        483\n",
            "koi_slogg             363\n",
            "koi_slogg_err1        468\n",
            "koi_slogg_err2        468\n",
            "koi_srad              363\n",
            "koi_srad_err1         468\n",
            "koi_srad_err2         468\n",
            "koi_kepmag              1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [feat for feat in features if feat not in ['koi_teq_err1', 'koi_teq_err2']]\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data[features] = imputer.fit_transform(data[features])\n",
        "\n",
        "# Display the shape of the data after imputation\n",
        "print(\"Data shape after imputation:\", data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXfrj5LnELjB",
        "outputId": "1264fce2-0782-4286-beb7-1861863cb8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape after imputation: (9564, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data[target] = label_encoder.fit_transform(data[target])\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AwWSN1EP7e",
        "outputId": "aace1523-ac4d-4179-d6ec-9228ed3c5e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[368  95  21]\n",
            " [ 63 423   4]\n",
            " [ 15   0 924]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79       484\n",
            "           1       0.82      0.86      0.84       490\n",
            "           2       0.97      0.98      0.98       939\n",
            "\n",
            "    accuracy                           0.90      1913\n",
            "   macro avg       0.87      0.87      0.87      1913\n",
            "weighted avg       0.90      0.90      0.90      1913\n",
            "\n",
            "Accuracy: 0.8964976476738108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The Random Forest algorithm was chosen for its ability to handle both classification and regression tasks, its robustness to overfitting, and its capability to handle high-dimensional datasets with a large number of features.\n",
        "\n",
        " It builds multiple decision trees during training and outputs the mode of the classes for classification tasks or the average prediction for regression tasks.\n",
        "\n",
        " It typically performs well across various types of datasets and is relatively easy to use with minimal hyperparameter tuning.\n"
      ],
      "metadata": {
        "id": "JAMxwMo9EjJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Tuning methods have not been explicitly implemented in the code. However,  Grid Search Cross-Validation, Randomized Search Cross-Validation, and Bayesian Optimization etc can be utilized"
      ],
      "metadata": {
        "id": "4zIKSznXEuJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Random Forest was chosen as the preferred algorithm for classifying exoplanets based on the \"koi_disposition\" column due to its robustness, scalability, and ability to handle high-dimensional data effectively. Compared to other algorithms such as Support Vector Machines, Gradient Boosting Machines, Logistic Regression, and k-Nearest Neighbors, Random Forest requires less parameter tuning while still achieving competitive performance. Its ensemble learning approach combines the strengths of decision trees, resulting in reliable predictions and ease of implementation.\n"
      ],
      "metadata": {
        "id": "c7V_ANKEGKUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The accuracy of the classification model is 0.8965, or approximately 89.65%."
      ],
      "metadata": {
        "id": "Q1zcD2mUG7he"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Confusion Matrix: It provides a tabular representation of the model's predictions, showing the number of true positive, true negative, false positive, and false negative predictions.\n",
        "\n",
        " Classification Report: It includes precision, recall, F1-score, and support for each class in the classification problem. Precision measures the accuracy of positive predictions, recall measures the ability of the model to correctly identify positive instances, and F1-score is the harmonic mean of precision and recall.\n",
        "\n",
        " Accuracy Score: It calculates the accuracy of the model, which is the proportion of correctly classified instances out of the total number of instances."
      ],
      "metadata": {
        "id": "wxokhuQQG8s6"
      }
    }
  ]
}